{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for RHESSys to train pyRHESSys \n",
    "## - Example: Coweeta subbasin 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the interactive Jupyter notebook to learn how to use pyRHESSys to simulate RHESSys. For this example, we want to simulate RHESSys at Coweeta subbasin 18. The workflow is below: \n",
    "\n",
    "1. Install pyRHESSys from GitHub (master branch of pyRHESSys)\n",
    "2. Download the RHESSys model instance of Coweeta subbasin 18 from HydroShare\n",
    "3. Download RHESSys execution file and compile the RHESSys model\n",
    "4. Examine the overview of Coweeta subbasin 18\n",
    "5. Review and create time-series input files\n",
    "6. Simulate RHESSys as single run\n",
    "7. Simulate RHESSys as ensemble runs\n",
    "8. Evaluate efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start the journey of pyRHESSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install pyRHESSys from GitHub (master branch of pyRHESSys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/bin/pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/bin/pip uninstall -y pyrhessys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/bin/pip install git+https://github.com/uva-hydroinformatics/pyRHESSys.git@master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the RHESSys Model Instance of Coweeta subbasin18 from HydroShare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyrhessys library \n",
    "import pyrhessys as pr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current directory\n",
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set HydroShare resource id of RHESSys Model instance for Coweeta subbasin18\n",
    "resource_id = '8bee0bfbf43d4d91b48242a8e6f66449'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download RHESSys Model instance of Coweeta subbasin18 from HydroSHare \n",
    "pr.utils.get_hs_resource(resource_id, current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download RHESSys execution file and complie the RHESSys model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in the current folder\n",
    "os.listdir(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory of model data folder\n",
    "model_path = current_path + \"/rhessys_coweeta_sub18\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download RHESSys source code from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {model_path} \n",
    "!git clone https://github.com/laurencelin/RHESSysEastCoast.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complie RHESSys 5.20.0 version execution file and set execution file to execution_file object\n",
    "execution_file = pr.utils.complie(model_path, version_option=\"5.20.0.develop\")\n",
    "execution_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_file = '/media/sf_pysumma/pyRHESSys/rhessys_coweeta_sub18/RHESSysEastCoast/rhessys5.20.0.develop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine the overview of Coweeta subbasin 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"background_coweeta_sub18_map.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Review and Create Time-Series input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas library to create pandas dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create pyRHESSys Simulation Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pr.Simulation(execution_file, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Review, modify or create input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in observed streamflow folder\n",
    "os.listdir(r.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandas Dataframe from observed streamflow\n",
    "obs_flow = pd.read_csv(os.path.join(r.obs + '/Qobs_18.csv' ))\n",
    "obs_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed streamflow\n",
    "obs_flow.plot(x=\"year\", y=\"mmd\", figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in observed climate data folder\n",
    "os.listdir(r.clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cwt.base text file in climate data folder\n",
    "clim_file = r.clim + '/cwt.base'\n",
    "clim_data = open(clim_file, 'r')\n",
    "print(clim_data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to change directories, you can use replace_string method\n",
    "pr.utils.replace_string(clim_file, \"clim\", r.clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cwt.base text file in climate data folder\n",
    "clim_file = r.clim + '/cwt.base'\n",
    "clim_data = open(clim_file, 'r')\n",
    "print(clim_data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in flows folder\n",
    "os.listdir(r.flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open flow.txt \n",
    "flow_file = r.flows + '/surfflow.txt'\n",
    "flow_data = open(flow_file, 'r')\n",
    "print(flow_data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in defs folder\n",
    "os.listdir(r.defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open soil_loam.def file\n",
    "soil_loam_file = r.defs + '/soil_loam_9.def'\n",
    "soil_loam_data = open(soil_loam_file, 'r')\n",
    "print(soil_loam_data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open hillslope_hillslope.def file\n",
    "hillslope_hillslope_file = r.defs + '/hillslope_hillslope.def'\n",
    "hillslope_hillslope_data = open(hillslope_hillslope_file, 'r')\n",
    "print(hillslope_hillslope_data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in world folder\n",
    "os.listdir(r.worldfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open world.hdr\n",
    "world_hdr_file = r.worldfiles + '/worldfile.hdr'\n",
    "world_hdr_data = open(world_hdr_file, 'r')\n",
    "print(world_hdr_data.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to change the direcotry for definition files cosidering this system, you can try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory for definition files considering this system\n",
    "pr.utils.replace_string(world_hdr_file, \"defs\", r.defs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to change the direcotry for base station files cosidering this system, you can try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory of base station file considering this system\n",
    "pr.utils.replace_string(world_hdr_file, \"clim\", r.clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the directory of world.hdr\n",
    "world_hdr_file = r.worldfiles + '/worldfile.hdr'\n",
    "world_hdr_data = open(world_hdr_file, 'r')\n",
    "print(world_hdr_data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check files in observed climate data folder\n",
    "os.listdir(r.tecfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the directory in climate base file\n",
    "tecfiles_file = r.tecfiles + '/tec_daily.txt'\n",
    "tecfiles_data = open(tecfiles_file, 'r')\n",
    "print(tecfiles_data.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Simulate RHESSys as a single run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Show and set parameters values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameter values from parameter_meta.json \n",
    "r.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter values \n",
    "r.parameters['version'] = 'rhessys5.20.0.develop'\n",
    "r.parameters['start_date'] = '2005 01 01 01'\n",
    "r.parameters['end_date'] = '2008 12 31 01'    #'2008 12 31 01'\n",
    "r.parameters['gw1'] = '0.117211997411679'\n",
    "r.parameters['gw2'] = '0.0659735129203182'\n",
    "r.parameters['s1'] = '10.1682388144545'\n",
    "r.parameters['s2'] = '0.997275193734094'\n",
    "r.parameters['s3'] = '1.84849880747497'\n",
    "r.parameters['snowEs'] = '0.605362305999734'\n",
    "r.parameters['snowTs'] = '1.02025739167741'\n",
    "r.parameters['sv1'] = '1.73747300930697'\n",
    "r.parameters['sv2'] = '172.427322705276'\n",
    "r.parameters['svalt1'] = '0.928032172983822'\n",
    "r.parameters['svalt2'] = '0.955452497987305'\n",
    "r.parameters['locationid'] = '1' # option \"0\": not use \"-p\", option \"1\": use only -p, option \"2\" : use -p with basin_id etc\n",
    "#r.parameters['basin_id'] = '1'\n",
    "#r.parameters['hillslope_id'] = '1'\n",
    "#r.parameters['zone_id'] = '1'\n",
    "#r.parameters['patch_id'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the change of parameter values\n",
    "r.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Execute RHESSys as a single run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the run method has an error during simulation. At this time, you can try the run again.If you still get an errors, it is probably due to different operating systems. In that case, you can copy commands from lines 1~9 of the generated running status below, and paste them into terminal window. Then you can check what the exact error is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can create some options to execute RHESSys considering different execution environments. \n",
    "# In this case, we use a local RHESSys execution file.\n",
    "# Near future, we will add more options such as Docker\n",
    "r.run(\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Plot output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you plot RHESSys daily output, you can use output variables (RHESSys Output Abbreviation) from the table below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basin Daily Output\n",
    " |                    RHESSys Output Abbreviation                   | Description |   Units |   \n",
    " |---------------------------------------------|-------------|-------------------|\n",
    " |         pot_surface_infil| Rain Throughfall    | mm          | \n",
    " |       snow_thr        | Snow Throughfall    | mm         | \n",
    " |sat_def_z  | Saturation Deficit with depth    | mm of depth          | \n",
    " |sat_def | Saturation Deficit - volume  | mm of water       | \n",
    " |rz_storage\t|Rooting Zone Storage\t|mm of water\n",
    " |unsat_stor|\tUnsaturated Storage\t|mm\n",
    " |rz_drainage|\tRooting Zone Drainage|\tmm\n",
    " |unsat_drain|\tUnsaturated| Storage\tmm\n",
    " |cap\t|Capillary Rise|\tmm\n",
    " |evap\t|Evaporation|\tmm\n",
    " |snowpack\t|Snow Water Equivalent (SWE)|\tmm\n",
    " |trans\t|Transpiration|\tmm\n",
    " |baseflow\t|Baseflow\t|mm\n",
    " |return\t|Return flow|\tmm\n",
    " |streamflow\t|Total Stream Outflow|\tmm (normalized by basin area)\n",
    " | psn\t|Net Photosynthesis\t|kgC/m2\n",
    "|lai\t|Leaf Area Index\t|m2/m2\n",
    "|gw.Qout\t|Groundwater Output\t|mm\n",
    "|gw.storage\t|Groundwater Store\t|mm\n",
    "|detention_store|\tDetention Store\t|mm\n",
    "|%sat_area|\tPercent Saturated Area\t|m2/m2\n",
    "|litter_store|\tLitter intercepted water Store\t|m2/m2\n",
    "|canopy_store|\tCanopy Intercepted water Store\t|m2/m2\n",
    "|%snow_cover|\tPercent Snow Cover\t|m2/m2\n",
    "|snow_subl|\tSnow Sublimation\t|\n",
    "|trans_var|\tSpatial variation in transpiration\t|\n",
    "|acc_trans\t\t||\n",
    "|acctransv_var\t\t||\n",
    "|pet\t|Potential Evapotranspiration|\tmm\n",
    "|dC13\t\t||\n",
    "|precip\t|Precipitation|\tmm\n",
    "|pcp_assim||\t\t\n",
    "|mortf\t|Fraction of Basin that have tree mortality\t|\n",
    "|tmax\t|Maximum Temperature\t|°C\n",
    "|tmin\t|Minimum Temperature\t|°C\n",
    "|tavg\t|Average Temperature\t|°C\n",
    "|vpd\t|Vapor Pressure Deficit\t|Pa\n",
    "|snowfall\t|Snowfall\t|\n",
    "|recharge\t|_Recharge of water to soil\t|\n",
    "|gpsn\t|Gross Photosynthesis\t|kgC/m2\n",
    "|resp\t|_ Respiration_\t|kgC/m2\n",
    "|gs\t|Canopy Conductance\t|mm/s?\n",
    "|rootdepth\t|Rooting depth\t|\n",
    "|plantc\t|Plant Carbon\t|kgC/m2\n",
    "|snowmelt\t|Snow Melt\t|\n",
    "|canopysubl\t|Canopy Sublimation\t|\n",
    "|routedstreamflow\t||\t\n",
    "|canopy_snow\t|Snow Intercepted on Canopy\t|\n",
    "|height\t|Canopy height\t|\n",
    "|evap_can\t|Canopy Evaporation?\t|\n",
    "|evap_lit\t|Litter Evaporation_\t|\n",
    "|evap_soil\t|Soil Evaporation_\t|\n",
    "|litrc\t|Litter Carbon_\t|\n",
    "|Kdown\t|Downward (from atmosphere) Direct Shortwave Radiation_\t|\n",
    "|Ldown\t|Downward (from atmosphere) Longwave Radiation_\t|\n",
    "|Kup\t|Reflected (upward) Shortwave Radiation_\t|\n",
    "|Lup\t|Reflected (upward) Longwave Radiation_\t|\n",
    "|Kstar_can\t|Absorbed shortwave by canopy\t|\n",
    "|Kstar_soil\t|Absorbed shortwave by soil\t|\n",
    "|Kstar_snow\t|Absorbed shortwave bysnow\t|\n",
    "|Lstar_can\t|Absorbed longwave by canopy\t|\n",
    "|Lstar_soil\t|Absorbed longwave by soil\t|\n",
    "|Lstar_snow\t|Absorbed longwave by snow\t|\n",
    "|LE_canopy\t|Latent heat evaporated by canopy\t|\n",
    "|LE_soil\tLa\t||\n",
    "|LE_snow\t\t||\n",
    "|Lstar_strat\t\t||\n",
    "|canopydrip\t\t||\n",
    "|ga\t|Aerodynamic Conductance\t|mm/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output files\n",
    "os.listdir(r.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe and set date index of mode output\n",
    "import pandas as pd\n",
    "plot_data = pd.read_csv(r.output + \"/rhessys_run\" +'_patch.daily', delimiter=\" \")\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Date column to Dateframe\n",
    "plot_data['Date'] = pd.to_datetime(plot_data[['year','month','day']])\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Map plotting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "def map_plot(plot_df, date, shp_path, variable, localID, vmin, vmax, annotation, pic_name):\n",
    "    daily_data = plot_data[\"Date\"] == date\n",
    "    daily_data_f = plot_data[daily_data]\n",
    "    shapes_df = gpd.read_file(shp_path, driver='ESRI Shapefile')\n",
    "    shapes_df = shapes_df[['gridcode','geometry']]\n",
    "    merged_df = gpd.GeoDataFrame(\\\n",
    "            pd.merge(\\\n",
    "            plot_data[plot_data['Date']==date][[variable, localID]], shapes_df,\n",
    "                left_on=localID, right_on='gridcode'))\n",
    "    # set a variable that will call whatever column we want to visualise on the map\n",
    "    variable = 'sat_def_z'\n",
    "\n",
    "    # set the range for the choropleth\n",
    "    vmin, vmax = 0.0, 1200\n",
    "\n",
    "    # abscreate figure and axes for Matplotlib\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "\n",
    "    # create map\n",
    "    merged_df.plot(column=variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "    # Now we can customise and add annotations\n",
    "\n",
    "    # remove the axis\n",
    "    ax.axis('off')\n",
    "\n",
    "    # add a title\n",
    "    ax.set_title(variable+' '+date, fontdict={'fontsize': '30','fontweight' : '3'})\n",
    "\n",
    "    # create an annotation for the  data source\n",
    "    ax.annotate(annotation,xy=(0.1, .08), xycoords='figure fraction',\n",
    "               horizontalalignment='left', verticalalignment='top',\n",
    "               fontsize=20, color='#555555')\n",
    "\n",
    "    # Create colorbar as a legend\n",
    "    sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm)\n",
    "\n",
    "    # this will save the figure as a high-res png. you can also save as svg\n",
    "    fig.savefig(\"maps/\"+pic_name, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of date\n",
    "import datetime\n",
    " \n",
    "start = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "date_array = (start + datetime.timedelta(days=x) for x in range(0, (end-start).days))\n",
    "\n",
    "date = []\n",
    "for date_object in date_array:\n",
    "    date1 = date_object.strftime(\"%Y-%m-%d\")\n",
    "    date.append(date1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of plot titles and figures name\n",
    "variable = 'sat_def_z'\n",
    "pic_name_list = []\n",
    "pic_file_name = []\n",
    "for one in date:\n",
    "    pic_name = variable + \"_\" + one\n",
    "    pic_name_list.append(pic_name)\n",
    "    pic_name = pic_name + \".png\"\n",
    "    pic_file_name.append(pic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values for map_plot method\n",
    "shp_path = \"/media/sf_pysumma/pyRHESSys/patch_plot/patch_test.shp\"\n",
    "variable = 'sat_def_z'\n",
    "localID = 'patchID'\n",
    "vmin = 0.0\n",
    "vmax = 1200\n",
    "annotation = 'Coweeta subbasin 18'\n",
    "start_date = '2005-01-01'\n",
    "end_date = '2008-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"maps\" folder to save figures using map_plot method\n",
    "!mkdir maps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create daily output figures during entire simulation periods as png format\n",
    "for i in range(len(pic_name_list)):\n",
    "    day =  date[i]\n",
    "    pic_name = pic_name_list[i]\n",
    "    map_plot(plot_data, day, shp_path, variable, localID, vmin, vmax, annotation, pic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create animation figures as gif format\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "image_path = Path('maps')\n",
    "images = list(image_path.glob('*.png'))\n",
    "images = images[2:]\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))\n",
    "imageio.mimwrite('animation.gif', image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='sat_def_z_2005-01-01.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='animated_from_images.gif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseris Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check observed stramflow from section 5.2 to check start date\n",
    "obs_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check observed stramflow from section 5.2 to check end date\n",
    "obs_flow.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date index \n",
    "date_index = pd.date_range(start='1936-11-01', end='2014-10-31', freq='D')\n",
    "date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date index\n",
    "obs_data = obs_flow.set_index(date_index)\n",
    "obs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip observed streamflow as the same with simulation period\n",
    "obs_data_f = obs_data['2005-01-01':'2008-12-31']\n",
    "obs_data_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple plot from simulation output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ts_plot(time series plot) method, you can select a sim_output_variable from the Basin Daily Output table in section 6.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plotting.ts_plot(plot_data, 'precip', sim_label=\"rainfall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plotting.ts_plot(plot_data, 'evap', sim_label=\"rainfall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plotting.ts_plot(plot_data, 'baseflow', sim_label=\"rainfall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_data.plot(subplots=True, figsize=(12,150))\n",
    "plt.xticks(plot_data[\"Date\"][:].values)\n",
    "plt.legend() # relocates legend to best location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plotting.ts_plot(plot_data, sim_output_variable ='streamflow', sim_label=\"sim_streamflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sometimes we need a warming period for certain initial periods of simulation. In this case, I recommend you to use the pre_trim setting to create an appropriate scale graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plotting.ts_plot(plot_data, sim_output_variable ='streamflow', sim_label=\"sim_streamflow\", pre_trim =100, post_trim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When users want to compare simulation streamflow and observed streamflow, users can use the \"ts_plot_obs\" method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare simulation streamflow and observed streamflow\n",
    "r.plotting.ts_plot_obs(sim_data=plot_data, sim_output_variable='streamflow', sim_label=\"sim_streamflow\", obs_data=obs_data_f, obs_variable=\"mmd\", obs_label=\"obs_stream\", pre_trim =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Efficiency evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HydroEval is an open-source evaluator for streamflow time series in Python. \"https://github.com/ThibHlln/hydroeval\"\n",
    "from hydroeval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set simulation and observation data to evaluate \n",
    "simulation_streamflow = plot_data[\"streamflow\"].values\n",
    "obs_streamflow = obs_data_f[\"mmd\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the evaluator with the Root Mean Square Error\n",
    "my_rmse = evaluator(rmse, simulation_streamflow[366:], obs_streamflow[366:-1])\n",
    "my_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the evaluator with the Nash Sutcliffe Efficiency\n",
    "my_nse = evaluator(nse, simulation_streamflow[366:], obs_streamflow[366:-1])\n",
    "my_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyRHESSys",
   "language": "python",
   "name": "pyrhessys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
